{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c9d760ec1d4941198f46d098d08b53c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6a40c8a4148f4765b5126f70ed639a43",
              "IPY_MODEL_af2ea43a1f614c86b4e1d9b5803c3be8",
              "IPY_MODEL_45476cadd2a54ee6a07e10db8d914078"
            ],
            "layout": "IPY_MODEL_821e768b642140639b0e90a1049dd0a3"
          }
        },
        "6a40c8a4148f4765b5126f70ed639a43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e5b2c7112544dbcb0c5deacacfa5b09",
            "placeholder": "​",
            "style": "IPY_MODEL_91ca5430aef34dc1b1a7393c0f7e42ab",
            "value": "Evaluating: 100%"
          }
        },
        "af2ea43a1f614c86b4e1d9b5803c3be8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea4fdb6ecb2246e0a8d3f18f2e2caf95",
            "max": 9,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4bebc464f8144c778a1e602a63dac099",
            "value": 9
          }
        },
        "45476cadd2a54ee6a07e10db8d914078": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94ce62a760934ea488aeee81ea3a9e88",
            "placeholder": "​",
            "style": "IPY_MODEL_c81568d759474f2684d9a041b771418a",
            "value": " 9/9 [02:18&lt;00:00,  6.60s/it]"
          }
        },
        "821e768b642140639b0e90a1049dd0a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e5b2c7112544dbcb0c5deacacfa5b09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91ca5430aef34dc1b1a7393c0f7e42ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ea4fdb6ecb2246e0a8d3f18f2e2caf95": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4bebc464f8144c778a1e602a63dac099": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "94ce62a760934ea488aeee81ea3a9e88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c81568d759474f2684d9a041b771418a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "!pip install ragas datasets pandas openai langchain\n",
        "\n",
        "# Import necessary libraries\n",
        "import json\n",
        "import pandas as pd\n",
        "from ragas import evaluate\n",
        "from ragas.metrics import faithfulness, answer_relevancy, context_precision\n",
        "from datasets import Dataset\n",
        "import os\n",
        "from typing import List, Dict, Any\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"✅ All packages installed and imported successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yn7nbAHzK59P",
        "outputId": "f1ba69f1-ca8b-4e52-876f-9e85ce241ebe"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ragas in /usr/local/lib/python3.11/dist-packages (0.3.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (4.0.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.97.1)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.26)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from ragas) (2.0.2)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (from ragas) (0.9.0)\n",
            "Requirement already satisfied: langchain-core in /usr/local/lib/python3.11/dist-packages (from ragas) (0.3.71)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.11/dist-packages (from ragas) (0.3.27)\n",
            "Requirement already satisfied: langchain_openai in /usr/local/lib/python3.11/dist-packages (from ragas) (0.3.28)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from ragas) (1.6.0)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.11/dist-packages (from ragas) (1.4.4)\n",
            "Requirement already satisfied: pydantic>=2 in /usr/local/lib/python3.11/dist-packages (from ragas) (2.11.7)\n",
            "Requirement already satisfied: diskcache>=5.6.3 in /usr/local/lib/python3.11/dist-packages (from ragas) (5.6.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.33.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.14.1)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.4.8)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.41)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.14)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.7.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.1.5)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core->ragas) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core->ragas) (1.33)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (3.11.0)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2->ragas) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2->ragas) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2->ragas) (0.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community->ragas) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community->ragas) (2.10.1)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community->ragas) (0.4.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->ragas) (2024.11.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->ragas) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->ragas) (0.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core->ragas) (3.0.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community->ragas) (1.1.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community->ragas) (1.1.0)\n",
            "✅ All packages installed and imported successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class RAGAsIntegrator:\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize the RAGAs integrator with required metrics.\"\"\"\n",
        "        self.metrics = [faithfulness, answer_relevancy, context_precision]\n",
        "        print(\"🚀 RAGAsIntegrator initialized with metrics: faithfulness, answer_relevancy, context_precision\")\n",
        "\n",
        "    def load_json_log(self, file_path: str) -> List[Dict[Any, Any]]:\n",
        "        \"\"\"Load the JSON log file.\"\"\"\n",
        "        try:\n",
        "            with open(file_path, 'r', encoding='utf-8') as file:\n",
        "                data = json.load(file)\n",
        "            print(f\"✅ Successfully loaded {file_path}\")\n",
        "            return data\n",
        "        except FileNotFoundError:\n",
        "            print(f\"❌ Error: File {file_path} not found.\")\n",
        "            return []\n",
        "        except json.JSONDecodeError:\n",
        "            print(f\"❌ Error: Invalid JSON format in {file_path}\")\n",
        "            return []\n",
        "\n",
        "    def prepare_dataset(self, log_data: List[Dict[Any, Any]]) -> Dataset:\n",
        "        \"\"\"Prepare dataset for RAGAs evaluation.\"\"\"\n",
        "        questions = []\n",
        "        answers = []\n",
        "        contexts = []\n",
        "        ground_truths = []  # Required for context_precision\n",
        "        item_ids = []\n",
        "\n",
        "        for item in log_data:\n",
        "            if 'items' in item:\n",
        "                for log_item in item['items']:\n",
        "                    system_prompt = \"\"\n",
        "                    user_prompt = \"\"\n",
        "                    context_list = []\n",
        "\n",
        "                    if 'input' in log_item:\n",
        "                        for input_item in log_item['input']:\n",
        "                            if input_item.get('role') == 'system':\n",
        "                                context_list.append(input_item.get('content', ''))\n",
        "                            elif input_item.get('role') == 'user':\n",
        "                                user_prompt = input_item.get('content', '')\n",
        "\n",
        "                    answer = log_item.get('expected_output', '')\n",
        "                    item_id = log_item.get('id', '')\n",
        "\n",
        "                    if user_prompt and answer:\n",
        "                        questions.append(user_prompt)\n",
        "                        answers.append(answer)\n",
        "                        contexts.append(context_list)  # RAGAs expects list of contexts\n",
        "                        ground_truths.append(answer)  # Use expected_output as ground_truth\n",
        "                        item_ids.append(item_id)\n",
        "\n",
        "        # Create dataset\n",
        "        dataset_dict = {\n",
        "            'question': questions,\n",
        "            'answer': answers,\n",
        "            'contexts': contexts,\n",
        "            'ground_truth': ground_truths,\n",
        "            'item_id': item_ids\n",
        "        }\n",
        "\n",
        "        dataset = Dataset.from_dict(dataset_dict)\n",
        "        print(f\"📊 Dataset prepared with {len(dataset)} items (including ground_truth for context_precision)\")\n",
        "        return dataset\n",
        "\n",
        "    def compute_ragas_metrics(self, dataset: Dataset) -> Dict[str, Any]:\n",
        "        \"\"\"Compute RAGAs metrics for the dataset.\"\"\"\n",
        "        try:\n",
        "            print(\"🔄 Computing RAGAs metrics... This may take a few minutes.\")\n",
        "            result = evaluate(\n",
        "                dataset=dataset,\n",
        "                metrics=self.metrics,\n",
        "            )\n",
        "            print(\"✅ RAGAs metrics computed successfully!\")\n",
        "            # Convert result to dictionary if it's a Dataset object\n",
        "            if isinstance(result, Dataset):\n",
        "                 return result.to_dict()\n",
        "            return result.scores  # Access the scores dictionary directly if it's a Result object\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error computing RAGAs metrics: {e}\")\n",
        "            print(\"Please check your API key, billing details, or try again later.\")\n",
        "            return {}\n",
        "\n",
        "    def format_output(self, dataset: Dataset, results: Dict[str, Any]) -> List[Dict[str, Any]]:\n",
        "        \"\"\"Format the output as required JSON structure.\"\"\"\n",
        "        output = []\n",
        "\n",
        "        # Check if results contain item-wise scores (which is the expected format from evaluate)\n",
        "        if all(metric.name in results and isinstance(results[metric.name], list) for metric in self.metrics):\n",
        "            for i, item_id in enumerate(dataset['item_id']):\n",
        "                item_result = {\n",
        "                    \"id\": item_id,\n",
        "                    \"faithfulness\": round(results.get('faithfulness', [0.0]*len(dataset))[i], 2),\n",
        "                    \"answer_relevancy\": round(results.get('answer_relevancy', [0.0]*len(dataset))[i], 2),\n",
        "                    \"context_precision\": round(results.get('context_precision', [0.0]*len(dataset))[i], 2)\n",
        "                }\n",
        "                output.append(item_result)\n",
        "            print(f\"📋 Output formatted for {len(output)} items with item-wise scores\")\n",
        "        else:\n",
        "             print(\"⚠️ Results do not contain expected item-wise scores format. Formatting with default values.\")\n",
        "             # Fallback or handle cases where item-wise scores are not available\n",
        "             for i, item_id in enumerate(dataset['item_id']):\n",
        "                 item_result = {\n",
        "                     \"id\": item_id,\n",
        "                     \"faithfulness\": 0.0, # Defaulting to 0 or handle differently\n",
        "                     \"answer_relevancy\": 0.0,\n",
        "                     \"context_precision\": 0.0\n",
        "                 }\n",
        "                 output.append(item_result)\n",
        "             print(f\"📋 Output formatted with default values for {len(output)} items\")\n",
        "\n",
        "\n",
        "        return output\n",
        "\n",
        "    def save_results(self, results: List[Dict[str, Any]], output_file: str):\n",
        "        \"\"\"Save results to JSON file.\"\"\"\n",
        "        try:\n",
        "            with open(output_file, 'w', encoding='utf-8') as file:\n",
        "                json.dump(results, file, indent=2, ensure_ascii=False)\n",
        "            print(f\"💾 Results saved to {output_file}\")\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error saving results: {e}\")\n",
        "\n",
        "print(\"✅ RAGAsIntegrator class defined successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Q_EsymrK-mM",
        "outputId": "94213a82-94ab-4270-b3cc-29de8e4d4e03"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ RAGAsIntegrator class defined successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create sample LLM log data (from assignment example)\n",
        "sample_log_data = [\n",
        "    {\n",
        "        \"metadata\": {\n",
        "            \"timestamp\": \"2025-07-27T10:00:00Z\",\n",
        "            \"model\": \"gpt-4\"\n",
        "        },\n",
        "        \"items\": [\n",
        "            {\n",
        "                \"id\": \"item-001\",\n",
        "                \"input\": [\n",
        "                    {\n",
        "                        \"role\": \"system\",\n",
        "                        \"content\": \"You are a helpful AI assistant specialized in explaining complex scientific concepts. You have access to comprehensive knowledge about physics, chemistry, and biology. Always provide accurate, evidence-based information and cite relevant scientific principles when explaining phenomena.\"\n",
        "                    },\n",
        "                    {\n",
        "                        \"role\": \"user\",\n",
        "                        \"content\": \"Can you explain how photosynthesis works and why it's important for life on Earth?\"\n",
        "                    }\n",
        "                ],\n",
        "                \"expected_output\": \"Photosynthesis is a crucial biological process where plants, algae, and some bacteria convert light energy (usually from the sun) into chemical energy stored in glucose. The process occurs in two main stages: the light-dependent reactions (in thylakoids) and the Calvin cycle (in the stroma). During photosynthesis, plants absorb carbon dioxide from the atmosphere and water from the soil, using chlorophyll to capture sunlight. The overall equation is: 6CO2 + 6H2O + light energy → C6H12O6 + 6O2. This process is vital for life on Earth because it produces oxygen that most organisms need to breathe and forms the base of food chains by converting inorganic materials into organic compounds that can be consumed by other organisms.\"\n",
        "            },\n",
        "            {\n",
        "                \"id\": \"item-002\",\n",
        "                \"input\": [\n",
        "                    {\n",
        "                        \"role\": \"system\",\n",
        "                        \"content\": \"You are an expert financial advisor with deep knowledge of investment strategies, market analysis, and personal finance management. Provide practical, actionable advice while explaining the reasoning behind your recommendations.\"\n",
        "                    },\n",
        "                    {\n",
        "                        \"role\": \"user\",\n",
        "                        \"content\": \"What are the key principles of diversification in investment portfolios?\"\n",
        "                    }\n",
        "                ],\n",
        "                \"expected_output\": \"Diversification is a fundamental investment strategy that involves spreading investments across various asset classes, sectors, and geographic regions to reduce risk. The key principles include: 1) Asset class diversification - combining stocks, bonds, real estate, and commodities; 2) Sector diversification - investing across different industries like technology, healthcare, finance; 3) Geographic diversification - including domestic and international markets; 4) Company size diversification - mixing large-cap, mid-cap, and small-cap stocks. The main benefit is that when one investment performs poorly, others may perform well, reducing overall portfolio volatility. However, diversification doesn't eliminate all risk and may limit potential returns during strong market periods.\"\n",
        "            },\n",
        "            {\n",
        "                \"id\": \"item-003\",\n",
        "                \"input\": [\n",
        "                    {\n",
        "                        \"role\": \"system\",\n",
        "                        \"content\": \"You are a culinary expert with extensive knowledge of international cuisines, cooking techniques, and food science. Provide detailed explanations about cooking methods and food preparation.\"\n",
        "                    },\n",
        "                    {\n",
        "                        \"role\": \"user\",\n",
        "                        \"content\": \"How does the Maillard reaction work in cooking and why is it important?\"\n",
        "                    }\n",
        "                ],\n",
        "                \"expected_output\": \"The Maillard reaction is a complex chemical process that occurs when proteins and sugars in food are heated together, typically at temperatures above 140°C (285°F). Named after French chemist Louis-Camille Maillard, this reaction creates hundreds of different flavor compounds and the characteristic brown color in many cooked foods. The process involves amino acids reacting with reducing sugars, forming new compounds that give foods their distinctive tastes and aromas. It's crucial in cooking because it's responsible for the flavors in seared meat, toasted bread, roasted coffee, baked goods, and many other foods. The reaction is enhanced by higher temperatures, lower moisture, and slightly alkaline conditions. Understanding the Maillard reaction helps cooks achieve better flavors through proper browning techniques.\"\n",
        "            }\n",
        "        ]\n",
        "    }\n",
        "]\n",
        "\n",
        "# Save sample data to file\n",
        "with open('llm_log.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(sample_log_data, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "print(\"📝 Sample log data created and saved as 'llm_log.json'\")\n",
        "print(f\"📊 Sample contains {len(sample_log_data[0]['items'])} items for evaluation\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8d3OFQhYK_am",
        "outputId": "beab5cd5-ed10-477f-dc38-dffc60449149"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📝 Sample log data created and saved as 'llm_log.json'\n",
            "📊 Sample contains 3 items for evaluation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up OpenAI API key using Colab secrets (secure way)\n",
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "# Verify if key is set (without printing the actual key)\n",
        "if \"OPENAI_API_KEY\" in os.environ:\n",
        "    print(\"🔑 OpenAI API key set successfully!\")\n",
        "else:\n",
        "    print(\"❌ OpenAI API key not set. Add it in Colab secrets and re-run this cell.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9WM0QNgfLCX9",
        "outputId": "1742c84e-570a-4d2a-a01c-49503d588066"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔑 OpenAI API key set successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the integrator\n",
        "integrator = RAGAsIntegrator()\n",
        "\n",
        "# Process the log file\n",
        "input_file = \"llm_log.json\"\n",
        "output_file = \"ragas_output.json\"\n",
        "\n",
        "print(\"🎯 Starting RAGAs integration process...\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Load and process data\n",
        "log_data = integrator.load_json_log(input_file)\n",
        "\n",
        "if log_data:\n",
        "    # Prepare dataset\n",
        "    dataset = integrator.prepare_dataset(log_data)\n",
        "\n",
        "    if len(dataset) > 0:\n",
        "        # Compute metrics\n",
        "        results = integrator.compute_ragas_metrics(dataset)\n",
        "\n",
        "        if results: # Check if results dictionary is not empty\n",
        "            # Format output\n",
        "            formatted_output = integrator.format_output(dataset, results)\n",
        "\n",
        "            # Save results\n",
        "            integrator.save_results(formatted_output, output_file)\n",
        "\n",
        "            print(\"=\" * 50)\n",
        "            print(\"🎉 RAGAs integration completed successfully!\")\n",
        "            print(f\"📊 Processed {len(formatted_output)} items\")\n",
        "            print(f\"📁 Results saved to '{output_file}'\")\n",
        "        else:\n",
        "            print(\"❌ Failed to compute RAGAs metrics or results are empty\")\n",
        "    else:\n",
        "        print(\"❌ No valid data found for evaluation\")\n",
        "else:\n",
        "    print(\"❌ Failed to load log data\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468,
          "referenced_widgets": [
            "c9d760ec1d4941198f46d098d08b53c0",
            "6a40c8a4148f4765b5126f70ed639a43",
            "af2ea43a1f614c86b4e1d9b5803c3be8",
            "45476cadd2a54ee6a07e10db8d914078",
            "821e768b642140639b0e90a1049dd0a3",
            "3e5b2c7112544dbcb0c5deacacfa5b09",
            "91ca5430aef34dc1b1a7393c0f7e42ab",
            "ea4fdb6ecb2246e0a8d3f18f2e2caf95",
            "4bebc464f8144c778a1e602a63dac099",
            "94ce62a760934ea488aeee81ea3a9e88",
            "c81568d759474f2684d9a041b771418a"
          ]
        },
        "id": "cNsrgdrwLFCQ",
        "outputId": "42870217-ce51-4630-e3b6-3499ca46ab48"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 RAGAsIntegrator initialized with metrics: faithfulness, answer_relevancy, context_precision\n",
            "🎯 Starting RAGAs integration process...\n",
            "==================================================\n",
            "✅ Successfully loaded llm_log.json\n",
            "📊 Dataset prepared with 3 items (including ground_truth for context_precision)\n",
            "🔄 Computing RAGAs metrics... This may take a few minutes.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluating:   0%|          | 0/9 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c9d760ec1d4941198f46d098d08b53c0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:ragas.executor:Exception raised in Job[6]: RateLimitError(Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}})\n",
            "ERROR:ragas.executor:Exception raised in Job[1]: RateLimitError(Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}})\n",
            "ERROR:ragas.executor:Exception raised in Job[7]: RateLimitError(Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}})\n",
            "ERROR:ragas.executor:Exception raised in Job[8]: RateLimitError(Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}})\n",
            "ERROR:ragas.executor:Exception raised in Job[5]: RateLimitError(Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}})\n",
            "ERROR:ragas.executor:Exception raised in Job[0]: RateLimitError(Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}})\n",
            "ERROR:ragas.executor:Exception raised in Job[3]: RateLimitError(Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}})\n",
            "ERROR:ragas.executor:Exception raised in Job[4]: RateLimitError(Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}})\n",
            "ERROR:ragas.executor:Exception raised in Job[2]: RateLimitError(Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}})\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ RAGAs metrics computed successfully!\n",
            "⚠️ Results do not contain expected item-wise scores format. Formatting with default values.\n",
            "📋 Output formatted with default values for 3 items\n",
            "💾 Results saved to ragas_output.json\n",
            "==================================================\n",
            "🎉 RAGAs integration completed successfully!\n",
            "📊 Processed 3 items\n",
            "📁 Results saved to 'ragas_output.json'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and display the results\n",
        "try:\n",
        "    with open('ragas_output.json', 'r', encoding='utf-8') as f:\n",
        "        results = json.load(f)\n",
        "\n",
        "    print(\"📊 RAGAs Evaluation Results:\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Create a DataFrame for better visualization\n",
        "    df = pd.DataFrame(results)\n",
        "\n",
        "    # Display results table\n",
        "    print(df.to_string(index=False))\n",
        "\n",
        "    print(\"\\n📈 Summary Statistics:\")\n",
        "    print(\"-\" * 30)\n",
        "    print(f\"Average Faithfulness: {df['faithfulness'].mean():.3f}\")\n",
        "    print(f\"Average Answer Relevancy: {df['answer_relevancy'].mean():.3f}\")\n",
        "    print(f\"Average Context Precision: {df['context_precision'].mean():.3f}\")\n",
        "\n",
        "    # Display individual results\n",
        "    print(\"\\n🔍 Detailed Results:\")\n",
        "    print(\"-\" * 30)\n",
        "    for result in results:\n",
        "        print(f\"ID: {result['id']}\")\n",
        "        print(f\"  Faithfulness: {result['faithfulness']}\")\n",
        "        print(f\"  Answer Relevancy: {result['answer_relevancy']}\")\n",
        "        print(f\"  Context Precision: {result['context_precision']}\")\n",
        "        print()\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(\"❌ Results file not found. Please run the integration first.\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Error displaying results: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zU6Y9UbALHZj",
        "outputId": "7125aac7-72b1-4425-b48d-50459bc291c5"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 RAGAs Evaluation Results:\n",
            "============================================================\n",
            "      id  faithfulness  answer_relevancy  context_precision\n",
            "item-001           0.0               0.0                0.0\n",
            "item-002           0.0               0.0                0.0\n",
            "item-003           0.0               0.0                0.0\n",
            "\n",
            "📈 Summary Statistics:\n",
            "------------------------------\n",
            "Average Faithfulness: 0.000\n",
            "Average Answer Relevancy: 0.000\n",
            "Average Context Precision: 0.000\n",
            "\n",
            "🔍 Detailed Results:\n",
            "------------------------------\n",
            "ID: item-001\n",
            "  Faithfulness: 0.0\n",
            "  Answer Relevancy: 0.0\n",
            "  Context Precision: 0.0\n",
            "\n",
            "ID: item-002\n",
            "  Faithfulness: 0.0\n",
            "  Answer Relevancy: 0.0\n",
            "  Context Precision: 0.0\n",
            "\n",
            "ID: item-003\n",
            "  Faithfulness: 0.0\n",
            "  Answer Relevancy: 0.0\n",
            "  Context Precision: 0.0\n",
            "\n"
          ]
        }
      ]
    }
  ]
}